model_cfgs:
  model_path: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
  model_args: {}
  tokenizer_args:
    model_max_length: 8192

data_cfgs:
  data_path: UCSC-VLAA/STAR-1
  data_size: null
  data_template: STAR-1
  load_configs:
    split: train
    num_proc: 8

training_cfgs:
  project_name: star1
  training_args:
    output_dir: ./output/sft
    per_device_train_batch_size: 1
    logging_strategy: steps
    logging_steps: 10
    save_strategy: epoch
    gradient_accumulation_steps: 2
    torch_empty_cache_steps: 1
    num_train_epochs: 5
    max_grad_norm: 1.0
    bf16: true
    fp16: false
    dataloader_num_workers: 8
    run_name: sft
    report_to: [wandb]
    torch_compile: false
    learning_rate: 5.e-5
    weight_decay: 5.e-6
    adam_beta1: 0.9
    adam_beta2: 0.99
    adam_epsilon: 1.e-8
    lr_scheduler_type: cosine
    warmup_ratio: 0.05
    # 跳过truncating
    max_length: null
